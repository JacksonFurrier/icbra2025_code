{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spect_cardiac.src.tools.manip.manip import normalize_volume\n",
    "\n",
    "# data fetching and handling\n",
    "from spect_cardiac.data.check_database import load_remote_data\n",
    "from spect_cardiac.data.fetch_data import fetch_data\n",
    "from spect_cardiac.src.tools.data.loadvolumes import LoadVolumes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import nrrd\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:1\") if use_cuda else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_loader = LoadVolumes()\n",
    "\n",
    "# initialize data fetching from remote, configuration is in data/remote.yml\n",
    "data_loaded = False\n",
    "url, datasets = load_remote_data()\n",
    "\n",
    "# read all filenames from the url\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get(url + '/recon/' + 'spie_2024/' + 'misc/' + 'label/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "label_names = []\n",
    "for label_ref in soup.find_all('a'):\n",
    "    label_names.append(label_ref.get('href'))\n",
    "\n",
    "page = requests.get(url + '/recon/' + 'spie_2024/' + 'misc/' + 'data/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "data_names = []\n",
    "for label_ref in soup.find_all('a'):\n",
    "    data_names.append(label_ref.get('href'))\n",
    "\n",
    "subjects = []\n",
    "subjects_data = []\n",
    "\n",
    "# fetch specific patient data\n",
    "for index in range(len(data_names)):\n",
    "\n",
    "    dicom_name = data_names[index]\n",
    "    label_name = label_names[index]\n",
    "    data_url = url + '/recon/' + 'spie_2024/' + 'misc/' + 'data/' + dicom_name\n",
    "    label_url = url + '/recon/' + 'spie_2024/' + 'misc/' + 'label/' + label_name\n",
    "    \n",
    "    # fetch the data from remote\n",
    "    data = fetch_data(data_url)\n",
    "    lab = fetch_data(label_url)\n",
    "    \n",
    "    # load data with the dicom loader\n",
    "    volume, data_loaded = dicom_loader.LoadSinglePatient(data)\n",
    "    header = nrrd.read_header(lab)\n",
    "    labels = nrrd.read_data(header, lab)\n",
    "    \n",
    "    # looks like the label export is a bit tricky so loading shall be updated\n",
    "    prob_val_1 = np.sum(np.where(np.transpose(labels, [2, 1, 0]) == 1, 1, 0))\n",
    "    prob_val_2 = np.sum(np.where(np.transpose(labels, [2, 1, 0]) == 2, 1, 0))\n",
    "    \n",
    "    if prob_val_1 > prob_val_2:\n",
    "        labels = np.where(np.transpose(labels, [2, 1, 0]) == 2, 1, 0)\n",
    "    else:\n",
    "        labels = np.where(np.transpose(labels, [2, 1, 0]) == 1, 1, 0)\n",
    "        \n",
    "    subject = {\n",
    "        'spect' : volume,\n",
    "        'left_ventricle' : labels\n",
    "    }\n",
    "    subjects.append(subject)\n",
    "    \n",
    "    age, gender, weight, height = dicom_loader.CalculatePatientStatistics()\n",
    "    subject_data = {\n",
    "        'age' : age,\n",
    "        'gender' : gender,\n",
    "        'weight' : weight,\n",
    "        'height' : height\n",
    "    }\n",
    "    subjects_data.append(subject_data)\n",
    "\n",
    "    # print(\"Volume shape: \", volume.shape, \"Labels shape:\", labels.shape)\n",
    "\n",
    "    # normalizing the frame values\n",
    "    normalize_volume(volume)\n",
    "\n",
    "assert (data_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_loader = LoadVolumes()\n",
    "\n",
    "# initialize data fetching from remote, configuration is in data/remote.yml\n",
    "data_loaded = False\n",
    "url, datasets = load_remote_data()\n",
    "\n",
    "# read all filenames from the url\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get(url + '/recon/' + 'spie_2024/' + 'bela/' + 'label/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "label_names = []\n",
    "for label_ref in soup.find_all('a'):\n",
    "    label_names.append(label_ref.get('href'))\n",
    "\n",
    "page = requests.get(url + '/recon/' + 'spie_2024/' + 'bela/' + 'data/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "data_names = []\n",
    "for label_ref in soup.find_all('a'):\n",
    "    data_names.append(label_ref.get('href'))\n",
    "\n",
    "subjects_bela = []\n",
    "subjects_bela_data = []\n",
    "\n",
    "# fetch specific patient data\n",
    "for index in range(len(data_names)):\n",
    "\n",
    "    dicom_name = data_names[index]\n",
    "    label_name = label_names[index]\n",
    "    data_url = url + '/recon/' + 'spie_2024/' + 'bela/' + 'data/' + dicom_name\n",
    "    label_url = url + '/recon/' + 'spie_2024/' + 'bela/' + 'label/' + label_name\n",
    "    \n",
    "    # fetch the data from remote\n",
    "    data = fetch_data(data_url)\n",
    "    lab = fetch_data(label_url)\n",
    "    \n",
    "    # load data with the dicom loader\n",
    "    volume, data_loaded = dicom_loader.LoadSinglePatient(data)\n",
    "    header = nrrd.read_header(lab)\n",
    "    labels = nrrd.read_data(header, lab)\n",
    "    \n",
    "    # looks like the label export is a bit tricky so loading shall be updated\n",
    "    prob_val_1 = np.sum(np.where(np.transpose(labels, [2, 1, 0]) == 1, 1, 0))\n",
    "    prob_val_2 = np.sum(np.where(np.transpose(labels, [2, 1, 0]) == 2, 1, 0))\n",
    "    \n",
    "    if prob_val_1 > prob_val_2:\n",
    "        labels = np.where(np.transpose(labels, [2, 1, 0]) == 2, 1, 0)\n",
    "    else:\n",
    "        labels = np.where(np.transpose(labels, [2, 1, 0]) == 1, 1, 0)\n",
    "    \n",
    "    subject = {\n",
    "        'spect' : volume,\n",
    "        'left_ventricle' : labels\n",
    "    }\n",
    "    subjects_bela.append(subject)\n",
    "    \n",
    "    age, gender, weight, height = dicom_loader.CalculatePatientStatistics()\n",
    "    subject_data = {\n",
    "        'age' : age,\n",
    "        'gender' : gender,\n",
    "        'weight' : weight,\n",
    "        'height' : height\n",
    "    }\n",
    "    subjects_bela_data.append(subject_data)\n",
    "\n",
    "    # print(\"Volume shape: \", volume.shape, \"Labels shape:\", labels.shape)\n",
    "\n",
    "    # normalizing the frame values\n",
    "    normalize_volume(volume)\n",
    "\n",
    "assert (data_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.config import print_config\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    CopyItemsd,\n",
    "    SpatialPadd,\n",
    "    EnsureChannelFirstd,\n",
    "    Spacingd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects_bela:\n",
    "    subjects.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "shuffled_subjects = random.sample(subjects, len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import set_determinism, first\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "train_size = 60\n",
    "val_size = 14\n",
    "test_size = 10\n",
    "\n",
    "for i in range(train_size):\n",
    "    train_data.append(shuffled_subjects[i])\n",
    "\n",
    "for j in range(train_size, train_size + val_size, 1):\n",
    "    val_data.append(shuffled_subjects[j])\n",
    "\n",
    "# for j in range(train_size + val_size, train_size + val_size + test_size, 1):\n",
    "#     test_data.append(shuffled_subjects[j])\n",
    "\n",
    "# Set Determinism\n",
    "set_determinism(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        EnsureChannelFirstd(keys=[\"spect\", 'left_ventricle'], channel_dim='no_channel'),\n",
    "        Spacingd(keys=[\"spect\", 'left_ventricle'], pixdim=(2.0, 2.0, 2.0), mode=(\"bilinear\")),\n",
    "        SpatialPadd(keys=[\"spect\", 'left_ventricle'], spatial_size=(64, 64, 64)),\n",
    "        # RandSpatialCropSamplesd(keys=[\"spect\", 'left_ventricle'], roi_size=(64, 64, 64), random_size=False, num_samples=2),\n",
    "        CopyItemsd(keys=[\"spect\", 'left_ventricle'], allow_missing_keys=False),\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nnFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnFormer.nnformer.network_architecture.nnFormer_synapse import nnFormer\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnformer_model = nnFormer(crop_size=[64,64,64],\n",
    "                embedding_dim=192,\n",
    "                input_channels=1, \n",
    "                num_classes=2, \n",
    "                conv_op=nn.Conv3d, \n",
    "                depths=[2,2,2,2],\n",
    "                num_heads=[6, 12, 24, 48],\n",
    "                patch_size=[2,4,4],\n",
    "                window_size=[4,4,8,4],\n",
    "                deep_supervision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nnformer_model.to(device)\n",
    "\n",
    "# Define Hyper-paramters for training loop\n",
    "max_epochs = 100 # it was 50\n",
    "val_interval = 1\n",
    "batch_size = 6\n",
    "# gradient_accumulation_steps = 4\n",
    "lr = 1e-5\n",
    "epoch_loss_values = []\n",
    "step_loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = 1000.0\n",
    "\n",
    "# Loss function\n",
    "loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Define DataLoader using MONAI, CacheDataset needs to be used\n",
    "train_ds = Dataset(data=train_data, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = Dataset(data=val_data, transform=train_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "\n",
    "        inputs, labels = (\n",
    "            batch_data[\"spect\"].to(device),\n",
    "            batch_data[\"left_ventricle\"].to(device)\n",
    "        )\n",
    "        \n",
    "        print(inputs.shape, labels.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Adjust the CL loss by Recon Loss\n",
    "        total_loss = loss_fn(outputs[0], labels)\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "        step_loss_values.append(total_loss.item())\n",
    "\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {total_loss.item():.4f}, \"\n",
    "        )\n",
    "\n",
    "    epoch_loss /= step\n",
    "\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if epoch % val_interval == 0:\n",
    "        print(\"Entering Validation for epoch: {}\".format(epoch + 1))\n",
    "        total_val_loss = 0\n",
    "        val_step = 0\n",
    "        model.eval()\n",
    "        for val_batch in val_loader:\n",
    "            val_step += 1\n",
    "            inputs, labels = (\n",
    "                val_batch[\"spect\"].to(device),\n",
    "                val_batch['left_ventricle'].to(device),\n",
    "            )\n",
    "            print(\"Input shape: {}\".format(inputs.shape))\n",
    "            outputs = model(inputs)\n",
    "            val_loss = loss_fn(outputs[0], labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        total_val_loss /= val_step\n",
    "        val_loss_values.append(total_val_loss)\n",
    "        print(f\"epoch {epoch + 1} Validation avg loss: {total_val_loss:.4f}\")\n",
    "\n",
    "        if total_val_loss < best_val_loss:\n",
    "            print(f\"Saving new model based on validation loss {total_val_loss:.4f}\")\n",
    "            best_val_loss = total_val_loss\n",
    "            checkpoint = {\"epoch\": max_epochs, \"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "            torch.save(checkpoint, \"spect_cardiac/nbs/batch_study_files/nnSynapse_100E_30D_6B.pt\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_loss_values)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_values)\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy as cp\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "import point_cloud_utils as pcu\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import mcubes\n",
    "from simpleicp import PointCloud, SimpleICP\n",
    "\n",
    "from spect_cardiac.src.algs.arm import lv_indicator\n",
    "from spect_cardiac.src.tools.recon.projector import forward_projector, backward_projector\n",
    "from spect_cardiac.src.tools.manip.manip import normalize_volume\n",
    "\n",
    "# data fetching and handling\n",
    "from spect_cardiac.data.check_database import load_remote_data\n",
    "from spect_cardiac.data.fetch_data import fetch_data\n",
    "from spect_cardiac.src.tools.data.loadvolumes import LoadVolumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_loader = LoadVolumes()\n",
    "\n",
    "# initialize data fetching from remote, configuration is in data/remote.yml\n",
    "data_loaded = False\n",
    "url, datasets = load_remote_data()\n",
    "\n",
    "# fetch specific patient data\n",
    "dicom_name = datasets['raw/']['turkey_par/'][10]\n",
    "data_url = url + '/raw/' + 'turkey_par/' + dicom_name\n",
    "\n",
    "# fetch the data from remote\n",
    "data = fetch_data(data_url)\n",
    "\n",
    "# load data with the dicom loader\n",
    "frames, data_loaded = dicom_loader.LoadSinglePatient(data)\n",
    "\n",
    "# normalizing the frame values\n",
    "normalize_volume(frames)\n",
    "frames = frames + 1\n",
    "\n",
    "assert (data_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames, width, height = frames.shape\n",
    "\n",
    "bprojectpor = backward_projector()\n",
    "lv_volume = bprojectpor(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lv_volume = np.random.rand(64, 64, 64)\n",
    "normalize_volume(lv_volume)\n",
    "\n",
    "num_prior = 9\n",
    "shape_priors = np.zeros([num_prior, *lv_volume.shape])\n",
    "\n",
    "wall_thickness = np.random.uniform(0.3, 1.0, num_prior)\n",
    "rot_angles = np.random.uniform(0, 2 * np.pi, num_prior)\n",
    "curvature = np.random.uniform(1.5, 3, num_prior)\n",
    "sigmas = np.random.uniform(-0.5, -1, num_prior)\n",
    "\n",
    "for i in range(num_prior):\n",
    "    volume = np.zeros([*lv_volume.shape])\n",
    "    params = dict(a=wall_thickness[i], c=curvature[i], sigma=sigmas[i])\n",
    "    rot_mx = R.from_quat([0, 0, np.sin(rot_angles[i]), np.cos(rot_angles[i])])\n",
    "\n",
    "    transform_params = [np.eye(3, 3), [16, 16, 0], 1.5]\n",
    "    shape_priors[i] = lv_indicator(volume, params, transform_params, a_plot=False)\n",
    "\n",
    "    recon_mode = 'basic'\n",
    "    fprojector = forward_projector(recon_mode)\n",
    "\n",
    "    frames = fprojector(shape_priors[i])\n",
    "    \n",
    "# lv_volume = shape_priors[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_shape_prior(shape_priors, kernel, sigma, centering_point):\n",
    "    \"\"\"\n",
    "    Nonlinear statistics shape prior based on kernel density estimation in the feature space\n",
    "        [1] Shape statistics in kernel space for variational image segmentation - Daniel Cremers, Timo Kohlberger,\n",
    "                                                                                  Christoph Schnoerr\n",
    "        [2] Active Shape Models - Their Training and Application - T. F. Cootes, C. J. Taylor, D. H. Cooper, J. Graham\n",
    "\n",
    "    Args:\n",
    "        z:\n",
    "        z_i:\n",
    "        sigma:\n",
    "\n",
    "    Returns:\n",
    "        energy:\n",
    "    \"\"\"\n",
    "    m = shape_priors.shape[0]\n",
    "    \n",
    "    E = (1 / m) * torch.ones([m, m], dtype=torch.float64)\n",
    "    K = torch.zeros([m, m], dtype=torch.float64)\n",
    "    \n",
    "    height, width, depth = shape_priors[0].shape\n",
    "    z_i = []\n",
    "    shape_face_count = torch.zeros([m], dtype=torch.int32)\n",
    "    shape_faces = []\n",
    "    for i in range(m):\n",
    "        verts_shape, tri_shape = mcubes.marching_cubes(shape_priors[i], 0.0)\n",
    "        cur_prior_shape = verts_shape / depth\n",
    "        \n",
    "        # set mesh size to 1 and move it to the centering point\n",
    "        verts_dist = cdist(cur_prior_shape, cur_prior_shape, 'euclidean')\n",
    "        verts_scaled = cur_prior_shape * 1.0 / verts_dist.max()\n",
    "        verts_scaled_translation = centering_point - verts_scaled.mean(axis=0)\n",
    "        verts_translated = verts_scaled + verts_scaled_translation \n",
    "\n",
    "        z_i.append(torch.from_numpy(verts_translated))\n",
    "        shape_faces.append(tri_shape)\n",
    "        shape_face_count[i] = tri_shape.shape[0]\n",
    "     \n",
    "    min_shape_face_count = shape_face_count.min()\n",
    "    # if k_til is wrongfully implemented or slow, or numerically unstable, \n",
    "    # then one can use K_til̃ = K − KE − EK + EKE\n",
    "    mean_shape = z_i[ int(m / 2) ] # try it with Wasserstein barycenter here compute the mean shape\n",
    "    mean_shape_face = shape_faces[ int(m / 2) ] # save the faces as well\n",
    "    \n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            K[i, j] = kernel(z_i[i], z_i[j], sigma)\n",
    "    \n",
    "    K_til= K - K @ E - E @ K + E @ K @ E\n",
    "    \n",
    "    # keep only real eigenvalues and eigenvectors\n",
    "    L, V = torch.linalg.eigh(K_til)\n",
    "    L = torch.flip(L, [0])\n",
    "    V = torch.fliplr(V)\n",
    "    \n",
    "    limit_val = 1e-6\n",
    "    if (L <= limit_val).any():\n",
    "        first_cplx = torch.where(L <= limit_val)[0][0]\n",
    "        sigma_ort = L[first_cplx - 1] / 2.0\n",
    "        \n",
    "        L[first_cplx:] = 0.0\n",
    "        V[:, first_cplx:] = 0.0\n",
    "        reg_mx = torch.eye(K.shape[0])\n",
    "        \n",
    "        Sigma_ort = V @ torch.diag(L) @ V.t() + sigma_ort * (reg_mx - V @ V.t())\n",
    "    else:  # bad bad things happen\n",
    "        first_cplx = -1\n",
    "        sigma_ort = 1\n",
    "        Sigma_ort = V @ torch.diag(L) @ V.t()\n",
    "    \n",
    "    return z_i, torch.linalg.inv(Sigma_ort), L, V, sigma_ort, sigma, first_cplx, min_shape_face_count, mean_shape, mean_shape_face, K.sum(), K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_til(k, sigma, x, y, z_i, m):\n",
    "    sum = 0\n",
    "    for i in range(m):\n",
    "        sum -= (1 / m) * (k(x, z_i[i], sigma) + k(y, z_i[i], sigma))\n",
    "\n",
    "    sum += k(x, y, sigma)\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "                sum += (1 / (m ** 2)) * k(z_i[i], z_i[j], sigma)\n",
    "\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_i needs some rescaling, named V[k, i] here\n",
    "def E_phi_grad_opt(V, kernel, k_m, k_matrix_sum, sigma, z_i, z, L, L_ort, r, m):\n",
    "    loss = torch.zeros(z.shape)\n",
    "    \n",
    "    # lightspeed optimized gradient computation\n",
    "    par_z = torch.zeros([m, *z.shape])\n",
    "    kernel_ = torch.zeros([m])\n",
    "    for i in range(m):\n",
    "        par_z[i] = torch.autograd.grad(kernel(z_i[i], z, sigma), [z])[0]\n",
    "        kernel_[i] = kernel(z_i[i], z, sigma)\n",
    "\n",
    "    k_til = kernel_ - (1/m) * kernel_.sum(dim=0) - (1 /m) * k_m.sum(dim=1) + (1 / (m ** 2)) * k_matrix_sum\n",
    "    \n",
    "    par_z_sum = (1 / m) * par_z.sum(dim = 0)\n",
    "    kernel_til = lambda par_z, index : par_z[index] - par_z_sum\n",
    "    \n",
    "    alpha = cp.copy(V)\n",
    "    alpha[:, :r] *= (torch.sqrt(L[:r])[:, None]).t()\n",
    "    \n",
    "    for k in range(r):\n",
    "        for i in range(m):\n",
    "            loss += (alpha[i, k] * k_til[i])  * (alpha[i, k] * kernel_til(par_z, i)) * (L[k] ** (-1) - L_ort ** (-1))\n",
    "            \n",
    "    par_zz = torch.zeros([*z.shape])\n",
    "    for k in range(m):\n",
    "        par_zz -= (1/m) * par_z[k]\n",
    "    loss += (L_ort ** (-1)) * par_zz\n",
    "    \n",
    "    return 2.0 * loss, k_til"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to try with different models from CV, e.g.: MS, Potts\n",
    "from geomloss import SamplesLoss\n",
    "eps = 5 * 1e-3\n",
    "loss_unbalanced = SamplesLoss(loss='sinkhorn', p=2, blur=eps, scaling=0.95)\n",
    "sigma = 5 * 1e0\n",
    "# k = lambda x, y, sigma : torch.exp(-loss(x, y) ** 2 / (2 * sigma ** 2))\n",
    "k = lambda x, y, sigma : torch.exp(-sigma * loss_unbalanced(x, y))\n",
    "centering_point = np.array([0.45, 0.45, 0.45])\n",
    "\n",
    "z_i, sigma_inv, L, V, sigma_ort, sigma, first_cplx, min_shape_face_count, mean_shape, mean_shape_face, k_matrix_sum, k_matrix  = nonlinear_shape_prior(shape_priors, kernel=k, sigma=sigma, centering_point=centering_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_prior(frames, min_shape_face_count, V, k, k_matrix, k_matrix_sum, sigma, z_i, L, sigma_ort, first_cplx):\n",
    "    \n",
    "    num_frames, width, height = frames.shape\n",
    "\n",
    "    bprojectpor = backward_projector()\n",
    "    lv_volume = bprojectpor(frames)\n",
    "    \n",
    "    normalize_volume(lv_volume)\n",
    "    verts, faces = mcubes.marching_cubes(lv_volume, 0.5)\n",
    "    min_shape_face_count = min(min_shape_face_count, faces.shape[0])\n",
    "    v_decimate, f_decimate, v_correspondence, f_correspondence = pcu.decimate_triangle_mesh(verts, faces.astype(np.int32), min_shape_face_count)\n",
    "    input_shape = torch.from_numpy(v_decimate / height)\n",
    "\n",
    "    m = len(z_i)\n",
    "    a_volume=torch.from_numpy(lv_volume)\n",
    "    rows, cols, height = a_volume.shape\n",
    "    z = v_decimate / cols\n",
    "    # z.requires_grad = True\n",
    "\n",
    "    # renorm to size 1 and translate it to center_point\n",
    "    z_dist = cdist(z, z, 'euclidean')\n",
    "    max_real_size = z_dist.max() * cols\n",
    "\n",
    "    z_scaled = torch.from_numpy(z * (1.0 / (z_dist.max())))\n",
    "    z_translation = z_scaled.mean(axis=0) - torch.from_numpy(centering_point)\n",
    "\n",
    "    # Project current shape on the mean shape as in [1]\n",
    "    pc_fix = PointCloud(mean_shape.detach().numpy(), columns=[\"x\", \"y\", \"z\"])\n",
    "    pc_mov = PointCloud((z_scaled - z_translation).detach().numpy(), columns=[\"x\", \"y\", \"z\"])\n",
    "    icp = SimpleICP()\n",
    "    icp.add_point_clouds(pc_fix, pc_mov)\n",
    "    H, proj_mean_icp, rigid_body_transformation_params, distance_residuals = icp.run(max_overlap_distance=1)\n",
    "\n",
    "    proj_mean = torch.from_numpy(proj_mean_icp)\n",
    "    proj_mean.requires_grad = True\n",
    "    grad_E, k_til = E_phi_grad_opt(V, k, k_matrix, k_matrix_sum, sigma, z_i, proj_mean, L, sigma_ort, first_cplx, m)\n",
    "    return grad_E, k_til"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_E, k_til = sample_prior(frames, min_shape_face_count, V, k, k_matrix, k_matrix_sum, sigma, z_i, L, sigma_ort, first_cplx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nnFormer + SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnFormer.nnformer.network_architecture.nnFormer_synapse import nnFormer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnformer_model = nnFormer(crop_size=[64,64,64],\n",
    "                embedding_dim=192,\n",
    "                input_channels=1, \n",
    "                num_classes=2, \n",
    "                conv_op=nn.Conv3d, \n",
    "                depths=[2,2,2,2],\n",
    "                num_heads=[6, 12, 24, 48],\n",
    "                patch_size=[2,4,4],\n",
    "                window_size=[4,4,8,4],\n",
    "                deep_supervision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nnformer_model.to(device)\n",
    "# Define Hyper-paramters for training loop\n",
    "max_epochs = 50 # it was 50\n",
    "val_interval = 1\n",
    "batch_size = 1\n",
    "# gradient_accumulation_steps = 4\n",
    "lr = 1e-5\n",
    "epoch_loss_values = []\n",
    "step_loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = 1000.0\n",
    "\n",
    "# Loss function\n",
    "loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Define DataLoader using MONAI, CacheDataset needs to be used\n",
    "train_ds = Dataset(data=train_data, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = Dataset(data=val_data, transform=train_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "\n",
    "        frames = batch_data['spect'].squeeze(0).squeeze(0)\n",
    "\n",
    "        grad_E, _ = sample_prior(frames, min_shape_face_count, V, k, k_matrix, k_matrix_sum, sigma, z_i, L, sigma_ort, first_cplx)\n",
    "\n",
    "        inputs, labels = (\n",
    "            batch_data['spect'].to(device),\n",
    "            batch_data[\"left_ventricle\"].to(device)\n",
    "        )\n",
    "        grad_E = grad_E.to(device)\n",
    "\n",
    "        print(inputs.shape, labels.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, grad_E)\n",
    "\n",
    "        # Adjust the CL loss by Recon Loss\n",
    "        total_loss = loss_fn(outputs[0], labels)\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "        step_loss_values.append(total_loss.item())\n",
    "\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {total_loss.item():.4f}, \"\n",
    "        )\n",
    "\n",
    "    epoch_loss /= step\n",
    "\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if epoch % val_interval == 0:\n",
    "        print(\"Entering Validation for epoch: {}\".format(epoch + 1))\n",
    "        total_val_loss = 0\n",
    "        val_step = 0\n",
    "        # model.eval()\n",
    "        for val_batch in val_loader:\n",
    "            val_step += 1\n",
    "            frames = val_batch['spect'].squeeze(0).squeeze(0)\n",
    "            grad_E, _ = sample_prior(frames, min_shape_face_count, V, k, k_matrix, k_matrix_sum, sigma, z_i, L, sigma_ort, first_cplx)\n",
    "\n",
    "\n",
    "            inputs, labels = (\n",
    "                val_batch[\"spect\"].to(device),\n",
    "                val_batch['left_ventricle'].to(device),\n",
    "            )\n",
    "            print(\"Input shape: {}\".format(inputs.shape))\n",
    "            outputs = model(inputs, grad_E.to(device))\n",
    "            val_loss = loss_fn(outputs[0], labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        total_val_loss /= val_step\n",
    "        val_loss_values.append(total_val_loss)\n",
    "        print(f\"epoch {epoch + 1} Validation avg loss: {total_val_loss:.4f}\")\n",
    "\n",
    "        if total_val_loss < best_val_loss:\n",
    "            print(f\"Saving new model based on validation loss {total_val_loss:.4f}\")\n",
    "            best_val_loss = total_val_loss\n",
    "            checkpoint = {\"epoch\": max_epochs, \"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "            torch.save(checkpoint, \"spect_cardiac/nbs/batch_study_files/nnSynapse_SP_50_60_1.pt\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_loss_values)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_values)\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwinUNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import SwinUNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_model = SwinUNETR(\n",
    "    img_size=(64,64,64),\n",
    "    in_channels=1,            # Number of input channels\n",
    "    out_channels=2,           # Number of output channels (e.g., for binary segmentation)\n",
    "    feature_size=48,          # Embedding size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = swin_model.to(device)\n",
    "\n",
    "# Define Hyper-paramters for training loop\n",
    "max_epochs = 50 # it was 50\n",
    "val_interval = 1\n",
    "batch_size = 2\n",
    "# gradient_accumulation_steps = 4\n",
    "lr = 1e-5\n",
    "epoch_loss_values = []\n",
    "step_loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = 1000.0\n",
    "\n",
    "# Loss function\n",
    "loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Define DataLoader using MONAI, CacheDataset needs to be used\n",
    "train_ds = Dataset(data=train_data, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = Dataset(data=val_data, transform=train_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "\n",
    "        inputs, labels = (\n",
    "            batch_data[\"spect\"].to(device),\n",
    "            batch_data[\"left_ventricle\"].to(device)\n",
    "        )\n",
    "        \n",
    "        print(inputs.shape, labels.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Adjust the CL loss by Recon Loss\n",
    "        total_loss = loss_fn(outputs, labels)\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "        step_loss_values.append(total_loss.item())\n",
    "\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {total_loss.item():.4f}, \"\n",
    "        )\n",
    "\n",
    "    epoch_loss /= step\n",
    "\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if epoch % val_interval == 0:\n",
    "        print(\"Entering Validation for epoch: {}\".format(epoch + 1))\n",
    "        total_val_loss = 0\n",
    "        val_step = 0\n",
    "        model.eval()\n",
    "        for val_batch in val_loader:\n",
    "            val_step += 1\n",
    "            inputs, labels = (\n",
    "                val_batch[\"spect\"].to(device),\n",
    "                val_batch['left_ventricle'].to(device),\n",
    "            )\n",
    "            print(\"Input shape: {}\".format(inputs.shape))\n",
    "            outputs = model(inputs)\n",
    "            val_loss = loss_fn(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        total_val_loss /= val_step\n",
    "        val_loss_values.append(total_val_loss)\n",
    "        print(f\"epoch {epoch + 1} Validation avg loss: {total_val_loss:.4f}\")\n",
    "\n",
    "        if total_val_loss < best_val_loss:\n",
    "            print(f\"Saving new model based on validation loss {total_val_loss:.4f}\")\n",
    "            best_val_loss = total_val_loss\n",
    "            checkpoint = {\"epoch\": max_epochs, \"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "            torch.save(checkpoint, \"spect_cardiac/nbs/batch_study_files/SwinUNetR_50E_60D_2B.pt\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_loss_values)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_values)\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
